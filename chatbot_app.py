"""
å£²ä¸Šãƒ‡ãƒ¼ã‚¿åˆ†æAIãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ (DuckDB + NLâ†’SQL)

Setup Commands:
uv add streamlit duckdb pandas plotly openai>=1.30.0
# For Anthropic API (optional):
# uv add anthropic

Run Command:
uv run streamlit run chatbot_app.py

Environment Variables:
OPENAI_API_KEY (required)
# or ANTHROPIC_API_KEY (if using Anthropic)
"""

import streamlit as st
import pandas as pd
import duckdb
import plotly.express as px
import plotly.graph_objects as go
import re
import os
from typing import Optional, Tuple
import io

# LLM Client Setup
try:
    import openai
    LLM_PROVIDER = "openai"
except ImportError:
    try:
        import anthropic
        LLM_PROVIDER = "anthropic"
    except ImportError:
        st.error("Please install either openai or anthropic: uv add openai>=1.30.0")
        st.stop()

# Required columns for validation
REQUIRED_COLUMNS = ['date', 'category', 'units', 'unit_price', 'region', 'sales_channel', 'customer_segment', 'revenue']

# Blocked SQL keywords for safety
BLOCKED_KEYWORDS = ['insert', 'update', 'delete', 'drop', 'alter', 'create', 'replace', 'attach', 'copy', 'pragma', 'script', 'call', ';']

def load_sales_data() -> pd.DataFrame:
    """Load and validate existing CSV data with required transformations"""
    csv_path = "data/sample_sales.csv"
    
    # Check if file exists
    if not os.path.exists(csv_path):
        st.error(f"âŒ Required file not found: {csv_path}")
        st.error("Please ensure the CSV file exists before running the application.")
        st.stop()
    
    try:
        # Load CSV
        df = pd.read_csv(csv_path)
        
        # Validate required columns
        missing_cols = set(REQUIRED_COLUMNS) - set(df.columns)
        if missing_cols:
            st.error(f"âŒ Missing required columns: {missing_cols}")
            st.error(f"Required columns: {REQUIRED_COLUMNS}")
            st.stop()
        
        # Convert date column to datetime
        df['date'] = pd.to_datetime(df['date'])
        
        # Fill missing revenue with units * unit_price (in-memory only)
        if df['revenue'].isnull().any():
            df['revenue'] = df['revenue'].fillna(df['units'] * df['unit_price'])
        
        return df
        
    except Exception as e:
        st.error(f"âŒ Error loading CSV file: {str(e)}")
        st.stop()

def init_duckdb(df: pd.DataFrame) -> duckdb.DuckDBPyConnection:
    """Initialize DuckDB with sales view"""
    con = duckdb.connect(':memory:')
    
    # Register DataFrame
    con.register('sales_df', df)
    
    # Create sales view with month column
    con.execute("""
        CREATE OR REPLACE VIEW sales AS
        SELECT
            date,
            date_trunc('month', date)::date AS month,
            category,
            units,
            unit_price,
            region,
            sales_channel,
            customer_segment,
            revenue
        FROM sales_df
    """)
    
    return con

def build_system_prompt(max_rows: int = 5000) -> str:
    """Build system prompt for LLM with strict constraints"""
    return f"""ã‚ãªãŸã¯æ—¢å­˜ã® sales ãƒ†ãƒ¼ãƒ–ãƒ«ã®ã¿ã‚’å¯¾è±¡ã¨ã™ã‚‹ DuckDBç”¨SQLã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã€‚

é‡è¦ãªåˆ¶ç´„:
- æ–°è¦ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆãƒ»ä»®å®šã¯ç¦æ­¢ã€‚æ—¢å­˜CSVã®å†…å®¹ã ã‘ã‚’å‰æã¨ã™ã‚‹
- SELECT æ–‡ã‚’1æœ¬ã ã‘å‡ºåŠ›ã€‚DDL/DML/è¤‡æ•°æ–‡/ã‚»ãƒŸã‚³ãƒ­ãƒ³ã¯ç¦æ­¢
- æœˆæ¬¡ã¯ month åˆ—ã‚’ä½¿ç”¨ã€‚ä¸æ˜ç­ãªã€Œå£²ä¸Šã€ã¯ SUM(revenue) ã¨è§£é‡ˆ
- å¿…è¦ã«å¿œã˜ LIMIT {max_rows} ã‚’ä»˜ä¸

ã‚¹ã‚­ãƒ¼ãƒ (sales ãƒ†ãƒ¼ãƒ–ãƒ«):
- date: æ—¥ä»˜
- month: æœˆåˆæ—¥ (date_trunc('month', date)::date)
- category: ã‚«ãƒ†ã‚´ãƒª
- units: æ•°é‡
- unit_price: å˜ä¾¡  
- region: åœ°åŸŸ
- sales_channel: è²©å£²ãƒãƒ£ãƒãƒ«
- customer_segment: é¡§å®¢ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ
- revenue: å£²ä¸Šé‡‘é¡

ä¾‹:
SELECT month, category, SUM(revenue) AS total_revenue
FROM sales
GROUP BY month, category
ORDER BY month, category

SELECT sales_channel, SUM(revenue) AS total_revenue
FROM sales
GROUP BY sales_channel
ORDER BY total_revenue DESC

SELECT region, SUM(revenue) AS total_revenue
FROM sales
GROUP BY region
ORDER BY total_revenue DESC

ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ãªã—ã§ç´”ç²‹ãªSQLã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"""

def generate_sql(user_msg: str) -> str:
    """Generate SQL using LLM API"""
    system_prompt = build_system_prompt()
    
    try:
        if LLM_PROVIDER == "openai":
            client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_msg}
                ],
                temperature=0.1,
                max_tokens=500
            )
            sql = response.choices[0].message.content.strip()
        
        # Uncomment below for Anthropic API
        # elif LLM_PROVIDER == "anthropic":
        #     client = anthropic.Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
        #     response = client.messages.create(
        #         model="claude-3-haiku-20240307",
        #         max_tokens=500,
        #         temperature=0.1,
        #         messages=[
        #             {"role": "user", "content": f"{system_prompt}\n\n{user_msg}"}
        #         ]
        #     )
        #     sql = response.content[0].text.strip()
        
        else:
            raise ValueError("No supported LLM provider available")
        
        # Remove code block markers if present
        sql = re.sub(r'```sql\s*', '', sql)
        sql = re.sub(r'```\s*', '', sql)
        sql = sql.strip()
        
        return sql
        
    except Exception as e:
        st.error(f"LLM API Error: {str(e)}")
        return fallback_sql(user_msg)

def is_safe_sql(sql: str) -> bool:
    """Check if SQL is safe to execute"""
    sql_lower = sql.lower().strip()
    
    # Check for blocked keywords
    for keyword in BLOCKED_KEYWORDS:
        if keyword in sql_lower:
            return False
    
    # Must start with SELECT
    if not sql_lower.startswith('select'):
        return False
    
    # Must be single statement (no semicolons)
    if ';' in sql:
        return False
    
    return True

def fallback_sql(user_msg: str) -> str:
    """Return fallback SQL based on user message patterns"""
    msg_lower = user_msg.lower()
    
    if any(word in msg_lower for word in ['æœˆ', 'ã‚«ãƒ†ã‚´ãƒª', 'category', 'month']):
        return """SELECT month, category, SUM(revenue) AS total_revenue
FROM sales
GROUP BY month, category
ORDER BY month, category"""
    
    elif any(word in msg_lower for word in ['ãƒãƒ£ãƒãƒ«', 'channel']):
        return """SELECT sales_channel, SUM(revenue) AS total_revenue
FROM sales
GROUP BY sales_channel
ORDER BY total_revenue DESC"""
    
    elif any(word in msg_lower for word in ['åœ°åŸŸ', 'region']):
        return """SELECT region, SUM(revenue) AS total_revenue
FROM sales
GROUP BY region
ORDER BY total_revenue DESC"""
    
    else:
        return """SELECT SUM(revenue) AS total_revenue FROM sales"""

def run_sql(con: duckdb.DuckDBPyConnection, sql: str) -> pd.DataFrame:
    """Execute SQL and return DataFrame"""
    # Add LIMIT if not present
    if 'limit' not in sql.lower():
        sql = sql.rstrip(';') + ' LIMIT 5000'
    
    try:
        result = con.execute(sql).df()
        return result
    except Exception as e:
        raise Exception(f"SQLå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}")

def auto_chart(df: pd.DataFrame) -> None:
    """Generate automatic chart based on DataFrame structure (Plotly Express, labels-based)"""
    if df.empty:
        return

    cols = df.columns.tolist()
    colset = set(cols)

    # å€™è£œåˆ—
    dim_candidates = ['category', 'sales_channel', 'region', 'customer_segment']
    val_candidates = ['total_revenue', 'total_units', 'revenue', 'units', 'count']

    # 1) month, category, total_revenue -> æŠ˜ã‚Œç·šï¼ˆè‰²=categoryï¼‰
    if {'month', 'category', 'total_revenue'}.issubset(colset):
        fig = px.line(
            df.sort_values('month'),
            x='month', y='total_revenue', color='category',
            title='æœˆåˆ¥ãƒ»ã‚«ãƒ†ã‚´ãƒªåˆ¥ å£²ä¸Šæ¨ç§»',
            labels={'month': 'æœˆ', 'total_revenue': 'å£²ä¸Š', 'category': 'ã‚«ãƒ†ã‚´ãƒª'}
        )
        st.plotly_chart(fig, use_container_width=True)
        return

    # 2) æ¬¡å…ƒÃ—å€¤ -> æ£’
    if len(cols) == 2:
        dim_col, value_col = cols[0], cols[1]
        if dim_col in dim_candidates and value_col in val_candidates:
            fig = px.bar(
                df,
                x=dim_col, y=value_col,
                title=f'{dim_col} åˆ¥ {value_col}',
                labels={dim_col: dim_col, value_col: value_col}
            )
            st.plotly_chart(fig, use_container_width=True)
            return

    # 3) monthÃ—å€¤ -> æŠ˜ã‚Œç·š
    if 'month' in colset:
        value_col = next((v for v in val_candidates if v in colset and v != 'month'), None)
        if value_col:
            fig = px.line(
                df.sort_values('month'),
                x='month', y=value_col,
                title=f'æœˆåˆ¥ {value_col} æ¨ç§»',
                labels={'month': 'æœˆ', value_col: value_col}
            )
            st.plotly_chart(fig, use_container_width=True)
            return

def summarize_result(df: pd.DataFrame) -> str:
    """Generate brief Japanese summary of results"""
    if df.empty:
        return "çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
    
    # Use first 50 rows for summary
    summary_df = df.head(50)
    rows = len(summary_df)
    total_rows = len(df)
    
    summary = f"çµæœ: {total_rows}ä»¶ã®ãƒ‡ãƒ¼ã‚¿"
    
    # Add basic stats if numeric columns exist
    numeric_cols = summary_df.select_dtypes(include=['number']).columns
    if len(numeric_cols) > 0:
        main_col = numeric_cols[0]
        total = summary_df[main_col].sum()
        avg = summary_df[main_col].mean()
        
        if 'revenue' in main_col.lower():
            summary += f"ã€ç·å£²ä¸Š: {total:,.0f}å††ã€å¹³å‡: {avg:,.0f}å††"
        elif 'units' in main_col.lower():
            summary += f"ã€ç·æ•°é‡: {total:,.0f}å€‹ã€å¹³å‡: {avg:,.1f}å€‹"
    
    if total_rows > rows:
        summary += f" (ä¸Šä½{rows}ä»¶ã‚’è¡¨ç¤º)"
    
    return summary

def main():
    """Main Streamlit application"""
    st.set_page_config(
        page_title="å£²ä¸Šãƒ‡ãƒ¼ã‚¿åˆ†æAIãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ",
        page_icon="ğŸ“Š",
        layout="wide"
    )
    
    st.title("ğŸ“Š å£²ä¸Šãƒ‡ãƒ¼ã‚¿åˆ†æAIãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ (DuckDB + NLâ†’SQL)")
    
    # Initialize session state
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # Load data and initialize DB
    with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™..."):
        sales_df = load_sales_data()
        con = init_duckdb(sales_df)
    
    # Sidebar - Data Overview
    with st.sidebar:
        st.header("ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿æ¦‚è¦")
        st.write(f"**ç·è¡Œæ•°**: {len(sales_df):,}ä»¶")
        st.write(f"**æœŸé–“**: {sales_df['date'].min().date()} ï½ {sales_df['date'].max().date()}")
        st.write(f"**ã‚«ãƒ†ã‚´ãƒªæ•°**: {sales_df['category'].nunique()}ç¨®é¡")
        st.write(f"**åœ°åŸŸæ•°**: {sales_df['region'].nunique()}åœ°åŸŸ")
        st.write(f"**ãƒãƒ£ãƒãƒ«æ•°**: {sales_df['sales_channel'].nunique()}ãƒãƒ£ãƒãƒ«")
        
        st.subheader("ğŸ’¾ å…ƒãƒ‡ãƒ¼ã‚¿ç¢ºèª")
        csv_exists = os.path.exists("data/sample_sales.csv")
        st.write(f"CSVå­˜åœ¨: {'âœ…' if csv_exists else 'âŒ'}")
        
        # Sample data preview
        if st.button("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º"):
            st.dataframe(sales_df.head())
    
    # Chat Interface
    st.subheader("ğŸ’¬ ãƒãƒ£ãƒƒãƒˆ")
    
    # Display chat messages
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.write(message["content"])
            if "sql" in message:
                st.code(message["sql"], language="sql")
            if "dataframe" in message:
                st.dataframe(message["dataframe"])
                auto_chart(message["dataframe"])
                if "summary" in message:
                    st.info(message["summary"])
                
                # Download button
                csv_buffer = io.StringIO()
                message["dataframe"].to_csv(csv_buffer, index=False)
                st.download_button(
                    label="ğŸ“¥ çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=csv_buffer.getvalue(),
                    file_name="query_result.csv",
                    mime="text/csv"
                )
    
    # Chat input
    if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šæœˆæ¯ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥ã®å£²ã‚Šä¸Šã’ã‚’è¦‹ã›ã¦ï¼‰"):
        # Add user message
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        with st.chat_message("user"):
            st.write(prompt)
        
        # Generate and execute SQL
        with st.chat_message("assistant"):
            with st.status("åˆ†æä¸­...", expanded=True) as status:
                st.write("ğŸ” SQLã‚’ç”Ÿæˆä¸­...")
                
                # Generate SQL
                generated_sql = generate_sql(prompt)
                
                st.write("ğŸ”’ ã‚»ãƒ¼ãƒ•ãƒ†ã‚£ãƒã‚§ãƒƒã‚¯ä¸­...")
                
                # Safety check
                if not is_safe_sql(generated_sql):
                    st.write("âš ï¸ ã‚»ãƒ¼ãƒ•ãƒ†ã‚£ãƒã‚§ãƒƒã‚¯å¤±æ•—ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯SQLã‚’ä½¿ç”¨")
                    generated_sql = fallback_sql(prompt)
                
                st.write("ğŸ“Š ã‚¯ã‚¨ãƒªå®Ÿè¡Œä¸­...")
                
                try:
                    # Execute SQL
                    result_df = run_sql(con, generated_sql)
                    
                    if result_df.empty:
                        st.warning("çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                        response_msg = {"role": "assistant", "content": "çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚åˆ¥ã®è³ªå•ã‚’è©¦ã—ã¦ã¿ã¦ãã ã•ã„ã€‚"}
                    else:
                        st.write("âœ¨ çµæœã‚’ç”Ÿæˆä¸­...")
                        summary = summarize_result(result_df)
                        
                        status.update(label="åˆ†æå®Œäº†!", state="complete", expanded=False)
                        
                        # Display results
                        st.write("**ç”Ÿæˆã•ã‚ŒãŸSQL:**")
                        st.code(generated_sql, language="sql")
                        
                        st.write("**å®Ÿè¡Œçµæœ:**")
                        st.dataframe(result_df)
                        
                        # Auto chart
                        auto_chart(result_df)
                        
                        # Summary
                        st.info(f"ğŸ“Š {summary}")
                        
                        # Download button
                        csv_buffer = io.StringIO()
                        result_df.to_csv(csv_buffer, index=False)
                        st.download_button(
                            label="ğŸ“¥ çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=csv_buffer.getvalue(),
                            file_name="query_result.csv",
                            mime="text/csv"
                        )
                        
                        response_msg = {
                            "role": "assistant", 
                            "content": "åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸã€‚",
                            "sql": generated_sql,
                            "dataframe": result_df,
                            "summary": summary
                        }
                
                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                    st.write("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯SQLã§å†è©¦è¡Œä¸­...")
                    
                    try:
                        fallback_query = fallback_sql(prompt)
                        result_df = run_sql(con, fallback_query)
                        
                        if not result_df.empty:
                            summary = summarize_result(result_df)
                            st.code(fallback_query, language="sql")
                            st.dataframe(result_df)
                            auto_chart(result_df)
                            st.info(f"ğŸ“Š {summary}")
                            
                            response_msg = {
                                "role": "assistant", 
                                "content": "ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚¯ã‚¨ãƒªã§çµæœã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚",
                                "sql": fallback_query,
                                "dataframe": result_df,
                                "summary": summary
                            }
                        else:
                            response_msg = {"role": "assistant", "content": "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚çµæœã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"}
                    except Exception as fallback_error:
                        st.error(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚‚å¤±æ•—ã—ã¾ã—ãŸ: {str(fallback_error)}")
                        response_msg = {"role": "assistant", "content": "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"}
        
        # Add assistant response to chat history
        st.session_state.messages.append(response_msg)

if __name__ == "__main__":
    main()